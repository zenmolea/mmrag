# Video-RAG Pipeline: æ¨¡å—åŒ–è§†é¢‘ç†è§£ç³»ç»Ÿ

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

## ğŸ“– é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ˜¯åŸºäº [Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension](https://arxiv.org/abs/2411.13093) è®ºæ–‡çš„æ”¹è¿›å®ç°ã€‚æˆ‘ä»¬å‚è€ƒäº†åŸå§‹ä»£ç åº“çš„è®¾è®¡æ€è·¯ï¼Œå¹¶è¿›è¡Œäº†ä»¥ä¸‹æ”¹è¿›ï¼š

- **æ¨¡å—åŒ–è®¾è®¡**ï¼šå°†åŸå§‹çš„å•ä½“ä»£ç é‡æ„ä¸ºç‹¬ç«‹çš„ç®¡é“æ¨¡å—
- **ä»£ç ä¼˜åŒ–**ï¼šç®€åŒ–äº†ä»£ç ç»“æ„ï¼Œæé«˜äº†å¯ç»´æŠ¤æ€§
- **æ˜“äºæ‰©å±•**ï¼šæ”¯æŒè½»æ¾æ·»åŠ æ–°çš„åŠŸèƒ½æ¨¡å—

### ğŸ¯ ä¸»è¦ç‰¹æ€§

- **ASRç®¡é“**ï¼šè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒéŸ³é¢‘è½¬å½•
- **OCRç®¡é“**ï¼šå…‰å­¦å­—ç¬¦è¯†åˆ«ï¼Œæå–è§†é¢‘ä¸­çš„æ–‡æœ¬ä¿¡æ¯
- **è§†é¢‘å¤„ç†ç®¡é“**ï¼šå¸§æå–ã€ç›®æ ‡æ£€æµ‹ã€åœºæ™¯æè¿°
- **æ¨ç†ç®¡é“**ï¼šLLaVAæ¨¡å‹æ¨ç†å’ŒRAGæ£€ç´¢
- **Promptç®¡ç†**ï¼šç»“æ„åŒ–çš„æç¤ºæ¨¡æ¿ç³»ç»Ÿ

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
mmrag/
â”œâ”€â”€ README.md                    # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ requirements.txt             # ä¾èµ–åŒ…åˆ—è¡¨
â”œâ”€â”€ setup_environment.py         # ç¯å¢ƒé…ç½®è„šæœ¬
â”œâ”€â”€ test_pipeline.ipynb          # æµ‹è¯•notebook
â”œâ”€â”€ evals/
â”‚   â”œâ”€â”€ generate_videomme.py     # ä¸»æ§åˆ¶æ–‡ä»¶
â”‚   â”œâ”€â”€ videomme_json_file.json  # æ•°æ®æ–‡ä»¶
â”‚   â””â”€â”€ pipline/                 # æ¨¡å—åŒ–ç®¡é“
â”‚       â”œâ”€â”€ asr_pipe.py          # ASRç®¡é“
â”‚       â”œâ”€â”€ ocr_pipe.py          # OCRç®¡é“
â”‚       â”œâ”€â”€ video_process.py     # è§†é¢‘å¤„ç†ç®¡é“
â”‚       â”œâ”€â”€ inference.py         # æ¨ç†ç®¡é“
â”‚       â””â”€â”€ prompts.py           # Promptæ¨¡æ¿
â”œâ”€â”€ vidrag_pipeline_simplified.py # ç®€åŒ–ç‰ˆæœ¬
â”œâ”€â”€ vidrag_pipeline.py           # åŸå§‹ç‰ˆæœ¬
â””â”€â”€ ape_tools/                   # APEå·¥å…·
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- CUDA 11.8+ (ç”¨äºGPUåŠ é€Ÿ)
- è‡³å°‘16GB GPUå†…å­˜

### è‡ªåŠ¨å®‰è£…

è¿è¡Œç¯å¢ƒé…ç½®è„šæœ¬ï¼š

```bash
python setup_environment.py
```

### æ‰‹åŠ¨å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone <your-repo-url>
cd mmrag
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
```bash
conda create -n mmrag python=3.10 -y
conda activate mmrag
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
```

4. **å®‰è£…LLaVA-NeXT**
```bash
git clone https://github.com/LLaVA-VL/LLaVA-NeXT
cd LLaVA-NeXT
pip install -e ".[train]"
cd ..
```

5. **å®‰è£…APE (ç”¨äºç›®æ ‡æ£€æµ‹)**
```bash
git clone https://github.com/shenyunhang/APE
cd APE
pip install -r requirements.txt
python -m pip install -e .
cd ..
```

### è¿è¡Œç¤ºä¾‹

1. **å¯åŠ¨APEæœåŠ¡**
```bash
cd APE/demo
python ape_service.py
```

2. **è¿è¡Œä¸»ç¨‹åº**
```bash
cd evals
python generate_videomme.py
```

3. **è¿è¡Œæµ‹è¯•notebook**
```bash
jupyter notebook test_pipeline.ipynb
```

## ğŸ“š ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

```python
from pipline.asr_pipe import ASRPipeline
from pipline.ocr_pipe import OCRPipeline
from pipline.video_process import VideoProcessPipeline
from pipline.inference import InferencePipeline

# åˆå§‹åŒ–ç®¡é“
asr_pipeline = ASRPipeline(model_name="whisper-large")
ocr_pipeline = OCRPipeline(languages=['en'])
video_pipeline = VideoProcessPipeline(max_frames_num=64)
inference_pipeline = InferencePipeline()

# å¤„ç†è§†é¢‘
video_path = "path/to/your/video.mp4"
frames, frame_time, video_time = video_pipeline.process_video(video_path)

# ASRå¤„ç†
asr_docs = asr_pipeline.process_video_asr(video_path)

# OCRå¤„ç†
ocr_docs = ocr_pipeline.get_ocr_docs(frames)

# æ¨ç†
question = "What is happening in the video?"
answer = inference_pipeline.process_question(question, frames, asr_docs, ocr_docs)
```

### é…ç½®å‚æ•°

ä¸»è¦é…ç½®å‚æ•°ä½äº `evals/generate_videomme.py`ï¼š

```python
max_frames_num = 64          # æœ€å¤§å¸§æ•°
USE_OCR = True              # å¯ç”¨OCR
USE_ASR = True              # å¯ç”¨ASR
USE_DET = True              # å¯ç”¨ç›®æ ‡æ£€æµ‹
```

## ğŸ”§ æ¨¡å—è¯´æ˜

### ASRç®¡é“ (`asr_pipe.py`)
- éŸ³é¢‘æå–å’Œåˆ†å—
- Whisperæ¨¡å‹è½¬å½•
- æ”¯æŒå¤šç§éŸ³é¢‘æ ¼å¼

### OCRç®¡é“ (`ocr_pipe.py`)
- æ–‡æœ¬æ£€æµ‹å’Œè¯†åˆ«
- å¤šè¯­è¨€æ”¯æŒ
- ç½®ä¿¡åº¦è¿‡æ»¤

### è§†é¢‘å¤„ç†ç®¡é“ (`video_process.py`)
- å¸§æå–å’Œé‡‡æ ·
- ç›®æ ‡æ£€æµ‹é›†æˆ
- åœºæ™¯æè¿°ç”Ÿæˆ

### æ¨ç†ç®¡é“ (`inference.py`)
- LLaVAæ¨¡å‹æ¨ç†
- RAGæ£€ç´¢
- CLIPç›¸ä¼¼åº¦è®¡ç®—

### Promptç®¡ç† (`prompts.py`)
- ç»“æ„åŒ–æç¤ºæ¨¡æ¿
- åŠ¨æ€æç¤ºç”Ÿæˆ
- å¤šæ¨¡æ€èåˆ

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

- **å†…å­˜ä¼˜åŒ–**ï¼šæ”¯æŒGPUå†…å­˜æ¸…ç†
- **æ‰¹å¤„ç†**ï¼šæ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘
- **ç¼“å­˜æœºåˆ¶**ï¼šASRç»“æœç¼“å­˜
- **å¹¶è¡Œå¤„ç†**ï¼šå¤šè¿›ç¨‹æ”¯æŒ

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œæµ‹è¯•notebook

```bash
jupyter notebook test_pipeline.ipynb
```

æµ‹è¯•notebookåŒ…å«ï¼š
- ç¯å¢ƒæ£€æŸ¥å’Œé…ç½®
- ä¾èµ–åŒ…éªŒè¯
- æ¨¡å—å¯¼å…¥æµ‹è¯•
- åŸºæœ¬åŠŸèƒ½æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- æ•…éšœæ’é™¤æŒ‡å—

### ç¯å¢ƒéªŒè¯

```bash
python setup_environment.py
```

è‡ªåŠ¨æ£€æŸ¥ï¼š
- Pythonç‰ˆæœ¬
- CUDAç¯å¢ƒ
- ä¾èµ–åŒ…å®‰è£…
- ç›®å½•ç»“æ„åˆ›å»º

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚

## ğŸ™ è‡´è°¢

æœ¬é¡¹ç›®åŸºäºä»¥ä¸‹å·¥ä½œï¼š

- **Video-RAGè®ºæ–‡**: [Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension](https://arxiv.org/abs/2411.13093)
- **åŸå§‹ä»£ç åº“**: [Video-RAG GitHub Repository](https://github.com/LLaVA-VL/LLaVA-NeXT)
- **LLaVA-NeXT**: å¼€æºå¤§è¯­è¨€è§†è§‰æ¨¡å‹
- **APE**: ç›®æ ‡æ£€æµ‹å·¥å…·

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤GitHub Issue
- å‘é€é‚®ä»¶è‡³ï¼š[your-email@example.com]

---

**æ³¨æ„**: æœ¬é¡¹ç›®ä»…ä¾›å­¦æœ¯ç ”ç©¶ä½¿ç”¨ï¼Œè¯·éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„å’Œä¼¦ç†å‡†åˆ™ã€‚ 